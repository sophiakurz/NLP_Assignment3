## Refining GNN-Based Fake News Detection: Replication Insights and Future Directions

The primary objective of this assignment is to design and enhance a Graph Neural Network (GNN)-based system for early fake news detection on social media by addressing key limitations in data preprocessing, feature extraction, and graph construction that were identified in both the original study and our replication. The goal is to develop a robust and efficient model that captures the nuanced propagation patterns of news on platforms such as Twitter, improves classification performance, reduces training complexity, and provides a foundation for adapting the approach to other tasks that lack strong neural baselines.

In our efforts to replicate “A Comparative Analysis of Graph Neural Networks for Fake News Detection,” the paper this assignment was based off of, we implemented a framework that mirrors the broad methodology outlined in the original study, despite its lack of a fully explicit methodological description. The original work discussed the use of the Twitter API to collect data along with preprocessing steps that removed non-essential elements like mentions, URLs, and reversed words; however, detailed instructions for data cleaning, augmentation, and feature extraction were not provided. Consequently, we were forced to make informed assumptions about these processes. Our replication involved cleaning tweet text through lowercasing and regex filtering, augmenting data via a synonym replacement strategy to mitigate class imbalance, extracting features using a TF-IDF vectorizer, and constructing graphs by connecting tweets based on a fixed k-nearest neighbor rule (with k set to five) determined by cosine similarity. These approximations were necessary due to both the absence of strict methodological details in the original study and limitations regarding data access, for instance, the original study relied on Twitter API data that is no longer publicly available, forcing us to source our data from a third-party provider.

The experimental results of our replication reveal that on the Twitter16 dataset, the BiSAGE model achieved the highest test accuracy of 81.71%, with BiARMA not far behind at 81.10%. The remaining models, BiGCN_A, BiGCN_B, BiGAT, and BiSGCN, produced accuracies in the mid- to high-70s range. On the Twitter15 dataset, BiSAGE again led with an accuracy of 85.91%, followed by BiARMA at 83.89%, while the other models ranged from approximately 78% to 80%. These numbers are notably lower than the original study’s reported accuracies of roughly 94% for both BiSAGE (Twitter16) and BiGCN-A (Twitter15). Several factors might explain these discrepancies, including differences in dataset composition due to the unavailability of the same Twitter API data and potential deviations stemming from our necessary approximations in preprocessing and model hyperparameter tuning.

A detailed error analysis of our replication has identified several key challenges. The synonym replacement process used for data augmentation, while effective in balancing class distributions, sometimes leads to semantic drift; for example, a tweet like “this news is lit, but so fake” might become “this news is blazing, but so fraudulent,” thereby losing essential colloquial nuances and leading to misclassification. In addition, the aggressive removal of non-alphanumeric characters eliminates important contextual cues such as emojis and hashtags, which are often critical for capturing the true sentiment or topical relevance of tweets. Moreover, the reliance on TF-IDF features, although straightforward in capturing word frequency and n-gram occurrences, falls short in representing deeper semantic context, especially in cases involving sarcasm or subtle humor. In terms of graph construction, using an undirected k-nearest neighbor approach based solely on cosine similarity does not differentiate between propagation (Top-Down) and dispersion (Bottom-Up) patterns, leading to potential over-smoothing where node representations become homogenized over layers of graph convolution. Such over-smoothing can render the nuanced information necessary for accurate fake news detection indistinguishable, thereby reducing overall model performance.

The limitations inherent in our project are also partly due to external factors. Because the original study obtained data directly through the Twitter API, which provided access to certain information now no longer available, we had to rely on a third-party source for our datasets. This likely introduced variations in both data composition and quality, which, coupled with the vague descriptions of data collection and preprocessing in the original study, required considerable guesswork on our part. These gaps in the original methodology contribute to inherent uncertainties in our replication process and may partly explain the observed performance gap.

In summary, while our replication shows consistent trends, particularly with the BiSAGE model demonstrating the best performance across both datasets, the absolute accuracy values remain lower than those reported in the original study. This is likely due to discrepancies in data sourcing, necessary assumptions in the absence of a strict methodology, and implementation differences in feature extraction and graph construction. Moving forward, our final project will aim to address these shortcomings by incorporating contextualized embeddings from pre-trained language models such as BERT or RoBERTa to capture richer semantic and contextual information, refining our graph construction process to build separate directed graphs that distinguish between propagation and dispersion patterns, and exploring adaptive edge weighting mechanisms with attention layers to mitigate over-smoothing. Adjustments to model architecture and training protocols, such as multi-head attention, additional skip connections, and more flexible dropout and early stopping criteria, are also planned. Furthermore, should the approach be adapted to new tasks like emerging topic detection or sentiment analysis where a strong neural baseline is absent, we intend to integrate additional signals (such as user metadata and temporal factors) into the feature extraction and graph construction pipelines. This comprehensive plan is designed to not only enhance early fake news detection on social media but also extend the applicability of GNN-based methods to other domains facing similar challenges.
